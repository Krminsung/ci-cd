# 🎬 Project Cukee: 감성 기반 AI 영화 큐레이션 서비스 기술 정의서

## 1. 개요 (Project Overview)
**Cukee(큐키)**는 단순한 메타데이터 기반 추천을 넘어, 사용자의 감정과 상황(Context)에 맞춰 영화를 전시회처럼 큐레이팅해주는 AI 서비스입니다. OTT 플랫폼 위에 오버레이되어 사용자에게 감성적인 영화 설명과 맞춤형 추천을 제공합니다.

---

## 2. 데이터 현황 (Data Assets)

### 2.1. 데이터 수집 구간 및 조건
* **수집 구간:** 1995년 ~ 2025년
* **TMDB 검색 조건:** 평점 0점 이상, 투표 수 5개 이상
* **Naver 검색 조건:** 해당 TMDB 영화 목록 기반 관람평 크롤링

### 2.2. 수집 현황 요약
| 구분 | 내용 | 저장 위치 |
| :--- | :--- | :--- |
| **TMDB 영화 메타데이터** | 총 **100,086개** (제목, 줄거리, 장르, 평점 등) | `json_data/` |
| **Naver 영화 관람평** | 총 **1,524,807개** (리뷰 텍스트) | `reviews_data/` |

<details>
<summary>🔻 연도별 데이터 상세 통계 (클릭하여 펼치기)</summary>

| 연도 | TMDB 영화 수 | Naver 리뷰 파일 수 | Naver 총 리뷰 개수 |
| :---: | :---: | :---: | :---: |
| 1995 | 1,396 | 203 | 16,016 |
| 1996 | 1,416 | 220 | 18,142 |
| 1997 | 1,507 | 230 | 23,606 |
| 1998 | 1,590 | 209 | 20,927 |
| 1999 | 1,684 | 243 | 23,782 |
| 2000 | 1,798 | 271 | 27,219 |
| 2001 | 1,950 | 260 | 31,037 |
| 2002 | 2,031 | 299 | 34,877 |
| 2003 | 2,125 | 298 | 43,477 |
| 2004 | 2,303 | 315 | 42,272 |
| 2005 | 2,531 | 354 | 52,323 |
| 2006 | 2,888 | 427 | 63,907 |
| 2007 | 3,099 | 453 | 61,493 |
| 2008 | 3,067 | 485 | 63,140 |
| 2009 | 3,279 | 467 | 60,690 |
| 2010 | 3,435 | 561 | 67,032 |
| 2011 | 3,653 | 641 | 72,690 |
| 2012 | 3,943 | 729 | 73,730 |
| 2013 | 4,290 | 824 | 70,405 |
| 2014 | 4,588 | 925 | 70,620 |
| 2015 | 4,797 | 908 | 64,739 |
| 2016 | 4,914 | 1,010 | 71,816 |
| 2017 | 5,319 | 1,068 | 70,440 |
| 2018 | 5,297 | 1,232 | 61,956 |
| 2019 | 5,178 | 1,191 | 59,403 |
| 2020 | 4,089 | 974 | 37,276 |
| 2021 | 4,158 | 1,010 | 46,820 |
| 2022 | 4,447 | 980 | 50,037 |
| 2023 | 4,180 | 879 | 51,537 |
| 2024 | 3,294 | 557 | 39,388 |
| 2025 | 1,840 | 383 | 34,010 |
| **합계** | **100,086** | **18,606** | **1,524,807** |

</details>

---

## 3. 서비스 아키텍처 및 흐름 (Service Architecture)

### 3.1. 사용자 경험 흐름 (UX Flow)
1.  **테마 선택:** 사용자가 11가지 감성 테마(예: "숏폼 러버 MZ 스타일", "설레고 싶은 날의 로맨스") 중 하나를 선택.
2.  **큐레이션 생성:** 백엔드에서 영화 20~30개를 선정하여 전시회 형태로 구성. AI가 전체 분위기를 분석해 해시태그(예: `#잔잔한 #힐링`) 자동 생성.
3.  **감성 설명 제공:** 영화 클릭 시, AI가 줄거리 요약 대신 **"큐레이터 톤의 감성 설명"**을 생성하여 제공.
4.  **AI 챗봇 인터랙션:** 사용자가 "좀 더 따뜻한 영화 추천해줘"와 같은 프롬프트 입력 시, 큐레이션을 실시간으로 재구성.

### 3.2. 개발 환경 (Environment)
* **CPU:** 4 vCPU
* **RAM:** 16GB
* **GPU:** NVIDIA Tesla T4 (16GB VRAM)
* **OS/Language:** Ubuntu / Python 3.10+
* **Framework:** PyTorch, Unsloth (학습 최적화)

---

## 4. AI 모델링 전략 (Modeling Strategy)

T4 GPU 환경에서의 효율성과 한국어 처리 능력을 고려하여 **경량화 모델(sLLM)**을 채택합니다.

### 4.1. 베이스 모델 (Base Model)
* **모델명:** `Llama-3.1-8B-Instruct` (또는 Llama-3-Open-Ko-8B)
* **선정 이유:**
    1.  **SOTA 성능:** 현존하는 8B 모델 중 추론 및 언어 이해력 최고 수준.
    2.  **리소스 효율:** 4-bit 양자화 적용 시 VRAM 6~8GB 점유로 T4에서 학습/추론 가능.
    3.  **한국어 지원:** 향상된 다국어 처리 능력.

### 4.2. 파인튜닝 방법론 (Methodology)
큐키 AI의 다면적인 능력(감성 표현, 논리적 추천, 선호도 반영)을 극대화하기 위해 3가지 전략을 비교 실험합니다.

| 전략 | 설명 | 목적 | 근거 논문 |
| :--- | :--- | :--- | :--- |
| **A. LoRA (SFT)** | 입력(영화정보)-출력(큐레이터 톤) 쌍 학습 | 큐레이터 페르소나 및 말투 모방 | *LoRA: Low-Rank Adaptation... (Hu et al., 2022)* |
| **B. CoT Tuning** | 추천의 '추론 과정(Why)'을 데이터에 포함하여 학습 | 복잡한 요구사항 분석 및 논리적 재구성 능력 강화 | *Chain-of-Thought Prompting... (Wei et al., 2022)* |
| **C. DPO** | 건조한 답변 vs 감성적 답변의 선호도 학습 | 사람(큐레이터)이 선호하는 감성 뉘앙스로 정렬(Alignment) | *Direct Preference Optimization... (Rafailov et al., 2023)* |

---

## 5. 고도화 파이프라인: Specialist + Generalist

단일 모델의 한계(할각화, 느린 속도)를 극복하기 위해 두 모델을 직렬로 연결하는 파이프라인 구조를 제안합니다.

### 5.1. 구조 (Architecture)
$$\text{Input (Reviews)} \xrightarrow{\text{Specialist Model}} \text{Sentiment/Tags} \xrightarrow{\text{Generalist Model}} \text{Final Curation Text}$$

1.  **Specialist (감성 분석기):** BERT 기반의 가벼운 모델. 리뷰를 분석하여 정확한 '감정 태그'와 '점수'를 추출.
2.  **Generalist (Llama-3.1):** 추출된 감정 정보를 바탕으로 매끄러운 '큐레이션 멘트' 작성.

### 5.2. 도입 효과 및 근거
* **할각화(Hallucination) 감소:** 분석된 팩트(Grounding)를 기반으로 글을 쓰므로 없는 내용을 지어내지 않음.
* **속도 향상:** 단순 분석은 가벼운 BERT가 담당하여 전체 처리 속도 최적화.
* **관련 연구:**
    * *Toolformer (Schick et al., 2023):* LLM이 외부 도구(분석 모델)를 사용할 때 정확도 상승.
    * *FrugalGPT (Chen et al., 2023):* 작은 모델과 큰 모델의 연계(Cascade)를 통한 비용/성능 최적화.

---

## 6. 데이터 엔지니어링 (Data Engineering)

보유한 Raw Data를 학습 가능한 'Golden Dataset'으로 변환하기 위해 **지식 증류(Knowledge Distillation)** 기법을 사용합니다.

### 6.1. 데이터 증강 전략 (Synthetic Data Generation)
* **방법:** GPT-4o API를 사용하여 Raw Data(줄거리/리뷰)를 바탕으로 '이상적인 큐레이터 코멘트'와 '추론 과정(CoT)'을 생성.
* **규모:** 약 2,000개 (Epoch 조절을 통해 T4 환경 최적화 학습)
* **이론적 배경:**
    * **Self-Instruct (Wang et al., 2023):** 소수의 씨앗 데이터로 거대 모델을 통해 고품질 데이터를 무한히 생성 가능함 증명.
    * **Stanford Alpaca (Taori et al., 2023):** Llama 모델을 GPT 생성 데이터로 학습시켜 고성능을 낸 대표 사례.
    * **Microsoft Orca (Mukherjee et al., 2023):** GPT-4의 추론 과정(Explanation Traces)을 학습 데이터로 활용.

---

## 7. 성능 평가 지표 (Evaluation Metrics)

정성적 평가와 정량적 평가를 병행하여 모델의 성능을 수치화합니다.

### 7.1. 해시태그 생성 능력 (Tag Generation)
* **지표:** **Cosine Similarity** 또는 **BERTScore**
* **방법:** Ground Truth 태그와 생성된 태그의 임베딩 벡터 유사도 측정. (1에 가까울수록 우수)

### 7.2. 감성 품질 (Emotional Quality)
* **지표:** **Style Classification Score** & **Perplexity (PPL)**
* **방법:** 별도 분류기를 통해 문장이 '감성적 큐레이터 톤'인지 판별(확률)하고, PPL로 문장의 자연스러움 측정.

### 7.3. 추천 적합성 (Recommendation Relevance)
* **지표:** **Metadata Match Rate** (Hit Rate)
* **수식:**
    $$\text{Accuracy} = \frac{\text{Number of Movies Meeting Criteria}}{\text{Total Recommended Movies}} \times 100$$
* **해석:** 사용자의 필터링 조건(예: "한국 영화만")을 얼마나 정확히 준수했는지 측정.
